{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_IMDB_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Drive Authentication"
      ],
      "metadata": {
        "id": "wQnq8yq44WOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "metadata": {
        "id": "IjU6PBBi4a4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PShFrMLuZL4s",
        "outputId": "af694404-4d5e-47bb-daa6-5480030a0054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "metadata": {
        "id": "FT_YG6ZOSg-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading the dataset"
      ],
      "metadata": {
        "id": "dTGzUlRd4dIP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8N0YdQIV8HL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Dlops project/IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:1000,:]"
      ],
      "metadata": {
        "id": "MhWdz99sEwJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0UkaFIZSaI28",
        "outputId": "7978533b-0ed4-49be-ef47-772e48c9b04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86505879-761f-475d-807a-33ae09a2b322\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86505879-761f-475d-807a-33ae09a2b322')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86505879-761f-475d-807a-33ae09a2b322 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86505879-761f-475d-807a-33ae09a2b322');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K7ZY7-QaN3b",
        "outputId": "6a7dbfb3-24eb-4879-8d32-71b5b9c1bd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a1b-scx1zv9Y",
        "outputId": "86618334-52b7-4e23-b2a3-91b720b6f625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8eee75d-124b-4fee-b08e-a196da3e4ea7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8eee75d-124b-4fee-b08e-a196da3e4ea7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f8eee75d-124b-4fee-b08e-a196da3e4ea7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f8eee75d-124b-4fee-b08e-a196da3e4ea7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sentiment.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVVRc9iI0jPr",
        "outputId": "dac49ef6-34cf-4f98-9d38-bf365aea009b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    501\n",
              "negative    499\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train test split"
      ],
      "metadata": {
        "id": "Mp0aVYDbgvfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_positive = df[df.sentiment==\"positive\"]\n",
        "df_negative = df[df.sentiment==\"negative\"]\n"
      ],
      "metadata": {
        "id": "8NiNkA92gu0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_positive))\n",
        "print(len(df_negative))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nEvpaoV0ozm",
        "outputId": "df85e052-b3c2-4eea-cda2-16a3fc77eecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "501\n",
            "499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_pos = df_positive.review\n",
        "y_pos = df_positive.sentiment\n",
        "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(X_pos, y_pos, test_size=0.4, random_state=42)\n",
        "\n",
        "X_neg = df_negative.review\n",
        "y_neg = df_negative.sentiment\n",
        "X_train_neg, X_test_neg, y_train_neg, y_test_neg = train_test_split(X_neg, y_neg, test_size=0.4, random_state=42)\n"
      ],
      "metadata": {
        "id": "wfkvhuAchDne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_pos.append(X_train_neg, ignore_index=True)\n",
        "X_test = X_test_pos.append(X_test_neg, ignore_index=True)\n",
        "y_train = y_train_pos.append(y_train_neg, ignore_index=True)\n",
        "y_test = y_test_pos.append(y_test_neg, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "ANsWpzuXhnEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlqgRorQ1JKB",
        "outputId": "441b9854-835f-4daa-a326-5fa64cc6f2c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599 401 599 401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_list_train = list(X_train)\n",
        "sentiment_list_train = list(y_train)\n",
        "df_train = pd.DataFrame(list(zip(review_list_train, sentiment_list_train)),\n",
        "               columns =['review', 'sentiment'])\n",
        "print(df_train.head)\n",
        "df_train = df_train.sample(frac = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xbi4MHbnnSXw",
        "outputId": "e116efe0-7d06-4e77-958b-79916888c09f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of                                                 review sentiment\n",
            "0    I had before a feeling of mislike for all Russ...  positive\n",
            "1    Overall I was rather impressed with the pilot....  positive\n",
            "2    This film held my interest enough to watch it ...  positive\n",
            "3    Riding high on the success of \"Rebel Without a...  positive\n",
            "4    If you like Sci-Fi, Monsters, and Ancient Lege...  positive\n",
            "..                                                 ...       ...\n",
            "594  A very ordinary made-for-tv product, \"Tyson\" a...  negative\n",
            "595  The story and the show were good, but it was r...  negative\n",
            "596  Time is precious. This film isn't. I must lear...  negative\n",
            "597  The Quick and the Undead is, finally, the firs...  negative\n",
            "598  This movie was a failure as a comedy and a fil...  negative\n",
            "\n",
            "[599 rows x 2 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_list_test = list(X_test)\n",
        "sentiment_list_test = list(y_test)\n",
        "df_valid = pd.DataFrame(list(zip(review_list_test, sentiment_list_test)),\n",
        "               columns =['review', 'sentiment'])\n",
        "\n",
        "df_valid = df_valid.sample(frac = 1)"
      ],
      "metadata": {
        "id": "azVsPWPWoTMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_train))\n",
        "print(len(df_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk2atcxaqxcA",
        "outputId": "60e03faf-cf1b-4286-90d4-0116ed7c1f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "599\n",
            "401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LgVMbKFy0IrT",
        "outputId": "99eb903c-5180-4591-c23b-cba621c9e258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                review sentiment\n",
              "275  It is incredible that there were two films wit...  negative\n",
              "239  Coen Brothers-wannabe from writer-director Pau...  negative\n",
              "263  it got switched off before the opening credits...  negative\n",
              "188  i am finally seeing the El Padrino movie, from...  positive\n",
              "143  This movie really woke me up, like it wakes up...  positive\n",
              "..                                                 ...       ...\n",
              "362  Pepe le Moko, played by Charles Boyer, is some...  negative\n",
              "86   For his first ever debut this film has some ri...  positive\n",
              "78   This PM Entertainment production is laced with...  positive\n",
              "111  So real and surreal, all in one. I remember fe...  positive\n",
              "251  This is probably the first entry in the \"Lance...  negative\n",
              "\n",
              "[401 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-354e6da3-d278-41c8-8e0c-4ec2f660c77d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>It is incredible that there were two films wit...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>Coen Brothers-wannabe from writer-director Pau...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>it got switched off before the opening credits...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>i am finally seeing the El Padrino movie, from...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>This movie really woke me up, like it wakes up...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>Pepe le Moko, played by Charles Boyer, is some...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>For his first ever debut this film has some ri...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>This PM Entertainment production is laced with...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>So real and surreal, all in one. I remember fe...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>This is probably the first entry in the \"Lance...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-354e6da3-d278-41c8-8e0c-4ec2f660c77d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-354e6da3-d278-41c8-8e0c-4ec2f660c77d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-354e6da3-d278-41c8-8e0c-4ec2f660c77d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_mapping = {\n",
        "    'positive': 0,\n",
        "    'negative': 1,\n",
        "}\n",
        "df_train['sentiment'] = df_train['sentiment'].map(sentiment_mapping)\n",
        "df_valid['sentiment'] = df_valid['sentiment'].map(sentiment_mapping)\n",
        "\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "7rtY68N58m28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Wm3me0im9ntb",
        "outputId": "e2081574-425b-4d75-ec94-30774b7cc70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                review  sentiment\n",
              "594  Attractive Marjorie(Farrah Fawcett)lives in fe...          0\n",
              "595  Savage Island (2003) is a lame movie. It's mor...          1\n",
              "596  These slasher pics are past their sell by date...          0\n",
              "597  What can I say? Not as bad as many here have m...          0\n",
              "598  Now I don't hate cheap movies. I just don't se...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb57d06d-6960-48b4-b3b0-5f1d11f728cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>Attractive Marjorie(Farrah Fawcett)lives in fe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>Savage Island (2003) is a lame movie. It's mor...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>These slasher pics are past their sell by date...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>What can I say? Not as bad as many here have m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>Now I don't hate cheap movies. I just don't se...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb57d06d-6960-48b4-b3b0-5f1d11f728cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb57d06d-6960-48b4-b3b0-5f1d11f728cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb57d06d-6960-48b4-b3b0-5f1d11f728cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3Hf8dXZ69qck",
        "outputId": "4b314635-2bee-443a-848a-997a7227f799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  It is incredible that there were two films wit...          1\n",
              "1  Coen Brothers-wannabe from writer-director Pau...          1\n",
              "2  it got switched off before the opening credits...          1\n",
              "3  i am finally seeing the El Padrino movie, from...          0\n",
              "4  This movie really woke me up, like it wakes up...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97c06577-298f-47b5-82c5-daf1e295cac7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It is incredible that there were two films wit...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Coen Brothers-wannabe from writer-director Pau...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it got switched off before the opening credits...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am finally seeing the El Padrino movie, from...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This movie really woke me up, like it wakes up...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97c06577-298f-47b5-82c5-daf1e295cac7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97c06577-298f-47b5-82c5-daf1e295cac7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97c06577-298f-47b5-82c5-daf1e295cac7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Distribution"
      ],
      "metadata": {
        "id": "weIM7pqZacak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.sentiment.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4gync2OaV5P",
        "outputId": "5e6a1440-9c4d-4043-be53-7351b4828035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    501\n",
              "negative    499\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "distribution = dict(df.sentiment.value_counts())\n",
        "sentiments = distribution.keys()\n",
        "counts = distribution.values()\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# creating the bar plot\n",
        "plt.bar(sentiments, counts, color ='green',\n",
        "        width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Sentiment\")\n",
        "plt.ylabel(\"Count of revies\")\n",
        "plt.title(\"Sentiment distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "RxlytZahaq_y",
        "outputId": "8ff00aa5-435a-4d09-fde4-ef63cb81730d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==3.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCbTRYmObD3F",
        "outputId": "640cdee1-8127-4c0f-b140-9d1d3b67eefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.0.53)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (21.3)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.8.0rc4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (0.1.96)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "Gdo9YyZA4l1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Importing Libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.optim import lr_scheduler\n",
        "from bs4 import BeautifulSoup \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "#import warnings\n",
        "#warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "JSeYs_Urcyzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D8l0ytOc2Wa",
        "outputId": "49d33aea-2663-45d0-dce4-8d5af5d2695d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sentiment Classifier\n",
        "This class defines the model architecture which is simply a fully-connected\n",
        "layer on top of a pre-trained BERT model."
      ],
      "metadata": {
        "id": "W_caNUzk4tG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  \"\"\"\n",
        "  This class defines the model architecture which is simply a fully-connected\n",
        "  layer on top of a pre-trained BERT model. \n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, BERT_MODEL):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(BERT_MODEL)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, 2) # Number of output classes = 2\n",
        "\n",
        "  def forward(self, ids, mask, token_type_ids):\n",
        "    last_hidden_state, pooled_output = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "metadata": {
        "id": "P-8muni8bEMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "BERT_MODEL = 'bert-base-uncased'\n",
        "model = SentimentClassifier(BERT_MODEL)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "-B8LMW6rySGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "scx4M_lk4zgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "x7dPIpps40YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFK8YW6VzF0z",
        "outputId": "2b80fb6e-4d49-43e4-a847-f162d36c35d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentClassifier(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (drop): Dropout(p=0.3, inplace=False)\n",
            "  (out): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utiliti Tokenizer\n",
        "This class tokenizes the input text using the pre-trained BERT tokenizer (wordpiece) and returns the corresponding tensors."
      ],
      "metadata": {
        "id": "DHgNbDQz47g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class util_tokenizer:\n",
        "  \"\"\"\n",
        "  This class tokenizes the input text using the pre-trained BERT tokenizer \n",
        "  (wordpiece) and returns the corresponding tensors.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, text, targets, tokenizer, max_len):\n",
        "    self.text = text\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.targets)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    text = str(self.text[item])\n",
        "    targets = self.targets[item]\n",
        "\n",
        "    inputs = self.tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        pad_to_max_length = True\n",
        "    )\n",
        "\n",
        "    ids = inputs[\"input_ids\"]\n",
        "    mask = inputs[\"attention_mask\"]\n",
        "    token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "    return {\n",
        "        \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "        \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "        \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        \"targets\": torch.tensor(targets, dtype=torch.long)\n",
        "    }"
      ],
      "metadata": {
        "id": "e24L5gpp57Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loss Function"
      ],
      "metadata": {
        "id": "B242cnNQ44Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(outputs, targets):\n",
        "\t\"\"\"\n",
        "\tThis function defines the loss function which is used to train the model, i.e.\n",
        "\tCrossEntropy.\n",
        "\t\"\"\"\n",
        "\treturn nn.CrossEntropyLoss(reduction='mean')(outputs, targets)"
      ],
      "metadata": {
        "id": "4P00jvKN57Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Function\n",
        "This function defines the training loop over the entire training set."
      ],
      "metadata": {
        "id": "bHB1V61q5Ey9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop_function(data_loader, model, optimizer, device):\n",
        "  \"\"\"\n",
        "  This function defines the training loop over the entire training set.\n",
        "  \"\"\"\n",
        "\n",
        "  model.train()\n",
        "  loss_list =[]\n",
        "  running_loss = 0.0\n",
        "  count=0\n",
        "  for bi, d in enumerate(data_loader):\n",
        "    #print(bi)\n",
        "    #print(d)\n",
        "    if(count%100 ==0):\n",
        "      print(count,\"count\")\n",
        "    count+=1\n",
        "    ids = d[\"ids\"]\n",
        "    mask = d[\"mask\"]\n",
        "    token_type_ids = d[\"token_type_ids\"]\n",
        "    targets = d[\"targets\"]\n",
        "    #print(ids,mask,token_type_ids,targets)\n",
        "\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "    targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "    loss = loss_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if bi % 10 == 0 and bi!=0:\n",
        "      temp = f'Batch index = {bi}\\tLoss = {running_loss/10}'\n",
        "      loss_list.append(running_loss/10)\n",
        "      running_loss = 0.0\n",
        "  return loss_list\n"
      ],
      "metadata": {
        "id": "1MVYT3gt57Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation Function\n",
        "This function defines the evaluation loop over the entire validation set.\n",
        "It also computes accuracy of the trained model, which is used to select the \n",
        "best model."
      ],
      "metadata": {
        "id": "4DgPa9125I-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_loop_function(data_loader, model, device):\n",
        "  \"\"\"\n",
        "  This function defines the evaluation loop over the entire validation set.\n",
        "  It also computes accuracy of the trained model, which is used to select the \n",
        "  best model.\n",
        "  \"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  corrects = 0\n",
        "  total = 0\n",
        "  for bi, d in enumerate(data_loader):\n",
        "    ids = d[\"ids\"]\n",
        "    mask = d[\"mask\"]\n",
        "    token_type_ids = d[\"token_type_ids\"]\n",
        "    targets = d[\"targets\"]\n",
        "\n",
        "    ids = ids.to(device, dtype=torch.long)\n",
        "    mask = mask.to(device, dtype=torch.long)\n",
        "    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "    targets = targets.to(device, dtype=torch.long)\n",
        "\n",
        "    outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total = total + targets.size(0)\n",
        "    corrects = corrects + (predicted==targets).sum().item()\n",
        "\n",
        "    #print(f\"bi: {bi}\\tPredicted: {predicted}\\tTargets: {targets}\")\n",
        "\n",
        "  accuracy = corrects / total * 100\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "_G7psDS957Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model"
      ],
      "metadata": {
        "id": "YbjOCwGT5fr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(df_train,df_valid):\n",
        "  \"\"\"\n",
        "  This function defines hyperparameters, model and optimizer, loads required\n",
        "  datasets and initiate the training and validation procedures.\n",
        "  \"\"\"\n",
        "  epoch_loss_list=[]\n",
        "  epoch_accuracy=[]\n",
        "  final_model=None\n",
        "\n",
        "  TRAIN_MAX_LEN = 140\n",
        "  VALID_MAX_LEN = 140\n",
        "  TRAIN_BATCH_SIZE = 16\n",
        "  VALID_BATCH_SIZE = 16\n",
        "  EPOCHS = 5\n",
        "  BERT_MODEL = 'bert-base-uncased'\n",
        "  LEARNING_RATE = 3e-5\n",
        "\n",
        "  tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "  train_dataset = util_tokenizer(\n",
        "      text = df_train['review'].values,\n",
        "      targets = df_train['sentiment'].values,\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = TRAIN_MAX_LEN\n",
        "  )\n",
        "\n",
        "\n",
        "  class_counts = []\n",
        "  for i in range(2):\n",
        "    class_counts.append(df_train[df_train['sentiment']==i].shape[0])\n",
        "  \n",
        "  \n",
        "  num_samples = sum(class_counts)\n",
        "  labels = df_train['sentiment'].values\n",
        "  class_counts=list(class_counts)\n",
        "  class_weights = []\n",
        "\n",
        "  for i in range(2):\n",
        "\n",
        "    if class_counts[i] != 0:\n",
        "      class_weights.append(num_samples/class_counts[i])\n",
        "    else:\n",
        "      class_weights.append(0)\n",
        "\n",
        "  weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
        "  sampler = torch.utils.data.sampler.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
        "\n",
        "\n",
        "  train_data_loader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size = TRAIN_BATCH_SIZE,\n",
        "      shuffle = False,\n",
        "      sampler = sampler\n",
        "  )\n",
        "\n",
        "  valid_dataset = util_tokenizer(\n",
        "      text = df_valid['review'].values,\n",
        "      targets = df_valid['sentiment'].values,\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = VALID_MAX_LEN\n",
        "  )\n",
        "\n",
        "  valid_data_loader = torch.utils.data.DataLoader(\n",
        "      valid_dataset,\n",
        "      batch_size = VALID_BATCH_SIZE,\n",
        "      shuffle = False\n",
        "  )\n",
        "\n",
        "  model = SentimentClassifier(BERT_MODEL)\n",
        "  model = model.to(device)\n",
        "\n",
        "  num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE * EPOCHS)\n",
        "  optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "  scheduler = lr_scheduler.StepLR(\n",
        "      optimizer,\n",
        "      step_size = 1,\n",
        "      gamma = 0.8\n",
        "  )\n",
        "  max_accuracy=-999\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "        print(\"Epoch : \",epoch,sep=\" \")\n",
        "        \n",
        "        loss_list= train_loop_function(data_loader=train_data_loader, model=model, optimizer=optimizer, device=device)\n",
        "      \n",
        "        accuracy = eval_loop_function(data_loader=valid_data_loader, model=model, device=device)\n",
        "        epoch_loss_list.append(loss_list)\n",
        "        epoch_accuracy.append(accuracy)\n",
        "        #accuracy_aspect_wise.append(accuracy)\n",
        "        if accuracy>max_accuracy :\n",
        "                max_accuracy=accuracy\n",
        "                final_model = model\n",
        "                model_name = '/content/drive/MyDrive/DLOPS_project'+ '/'+ str(epoch) + '.bin'\n",
        "                #epoch , accuracy in that epoch, loss batch wise \n",
        "                #accuracy_dict[aspect]= [epoch,accuracy,loss_list]\n",
        "\n",
        "        print(f\"\\nEpoch = {epoch}\\tAccuracy Score = {accuracy}\")\n",
        "        print(f\"Learning Rate = {scheduler.get_lr()[0]}\\n\")\n",
        "        print(\"loss_list \",loss_list,sep= \" \")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "  torch.save(final_model.state_dict(),model_name)     \n",
        "  return epoch_loss_list,epoch_accuracy\n"
      ],
      "metadata": {
        "id": "x7yHoAFJ57Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  epoch_loss_list,epoch_accuracy = run(df_train,df_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fff356-3ae0-41c8-b251-08abc4ef8cd6",
        "id": "8tnlFbEa3gBk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  0\n",
            "Train Loop\n",
            "Iteration 0 Loss 1.0711952447891235\n",
            "Iteration 100 Loss 0.4316503405570984\n",
            "Iteration 200 Loss 0.26546552777290344\n",
            "Iteration 300 Loss 0.22568006813526154\n",
            "Iteration 400 Loss 0.12127146124839783\n",
            "Iteration 500 Loss 0.38499605655670166\n",
            "Iteration 600 Loss 0.2438974678516388\n",
            "Iteration 700 Loss 0.3392295837402344\n",
            "Iteration 800 Loss 0.44453632831573486\n",
            "Iteration 900 Loss 0.6335721015930176\n",
            "Iteration 1000 Loss 0.4639115631580353\n",
            "Iteration 1100 Loss 0.26569733023643494\n",
            "Iteration 1200 Loss 0.25288426876068115\n",
            "Iteration 1300 Loss 0.12764817476272583\n",
            "Iteration 1400 Loss 0.3234763741493225\n",
            "Iteration 1500 Loss 0.35244235396385193\n",
            "Iteration 1600 Loss 0.2062813639640808\n",
            "Iteration 1700 Loss 0.18029427528381348\n",
            "Iteration 1800 Loss 0.22197669744491577\n",
            "\n",
            "Epoch = 0\tAccuracy Score = 88.47\n",
            "Learning Rate = 3e-05\n",
            "\n",
            "loss_list  [0.9767411470413208, 0.7653391242027283, 0.743639075756073, 0.7123958528041839, 0.6443391561508178, 0.5642549753189087, 0.3898644521832466, 0.41001539677381516, 0.41975760608911517, 0.32211055159568786, 0.3426187664270401, 0.4125638216733932, 0.3561225190758705, 0.39335491210222245, 0.3244102120399475, 0.3283058494329453, 0.4017381951212883, 0.35844912976026533, 0.332601098716259, 0.32942242473363875, 0.4042396187782288, 0.3631469182670116, 0.3583490699529648, 0.28642401844263077, 0.2623704820871353, 0.28345210254192355, 0.4707620605826378, 0.365095229446888, 0.3382487930357456, 0.33672402799129486, 0.2816333591938019, 0.2892885558307171, 0.3415087729692459, 0.3726701319217682, 0.33427727073431013, 0.3042860135436058, 0.26940587908029556, 0.3810739263892174, 0.2802108511328697, 0.30742203295230863, 0.30504862517118453, 0.30250738225877283, 0.3548796087503433, 0.3958543390035629, 0.3393747016787529, 0.30264461860060693, 0.20890641808509827, 0.242512147128582, 0.31421291902661325, 0.2603985361754894, 0.324960945546627, 0.207986930757761, 0.2841197054833174, 0.2583551533520222, 0.27721886783838273, 0.2480097770690918, 0.35128810070455074, 0.28963714092969894, 0.28593289032578467, 0.2702177006751299, 0.3425013706088066, 0.30684210658073424, 0.25213164240121844, 0.27562390491366384, 0.2544014912098646, 0.2833260789513588, 0.303573751449585, 0.26798765659332274, 0.17497403621673585, 0.3030027338303626, 0.24175652116537094, 0.3199386179447174, 0.3082639366388321, 0.26266985312104224, 0.20096095204353331, 0.2742362253367901, 0.1600255573168397, 0.3175851911306381, 0.23943101279437543, 0.21443621888756753, 0.3278088167309761, 0.34775562435388563, 0.20453450754284858, 0.23373497053980827, 0.28387969322502615, 0.2463430441915989, 0.21237121447920798, 0.3338742025196552, 0.2677302986383438, 0.2404661186039448, 0.30655461028218267, 0.22013551816344262, 0.27532562240958214, 0.24060831889510154, 0.2394416742026806, 0.2539994940161705, 0.2634256064891815, 0.2312508888542652, 0.23571408689022064, 0.26266081929206847, 0.35013626217842103, 0.31228591352701185, 0.20822650454938413, 0.18628984615206717, 0.26206560954451563, 0.27992490455508234, 0.28603352457284925, 0.295204658806324, 0.225092513859272, 0.22451725006103515, 0.28011095970869065, 0.2204118087887764, 0.21957099214196205, 0.24019134268164635, 0.2007587380707264, 0.2552637368440628, 0.2905057996511459, 0.1873101443052292, 0.3455051317811012, 0.29363169968128205, 0.24662268608808519, 0.27384198233485224, 0.18493417128920556, 0.21524277571588754, 0.19705786220729352, 0.2978394582867622, 0.17896997705101966, 0.2729428671300411, 0.1994499646127224, 0.22521160468459128, 0.25217778235673904, 0.2132646769285202, 0.22276385203003884, 0.22325552441179752, 0.16202969886362553, 0.26085891127586364, 0.17687899451702832, 0.2473523274064064, 0.20476189032196998, 0.21365225240588187, 0.24840572234243155, 0.19349701330065727, 0.2559411503374577, 0.2991805039346218, 0.26507181003689767, 0.15670111030340195, 0.15070978160947562, 0.20163436979055405, 0.24725773967802525, 0.2801283597946167, 0.2323703095316887, 0.2475916936993599, 0.28621530532836914, 0.2624227896332741, 0.3073883607983589, 0.24700175151228904, 0.22064572498202323, 0.29099262580275537, 0.17101843617856502, 0.2719491545110941, 0.2510338440537453, 0.22485074549913406, 0.19043042585253717, 0.1640867803245783, 0.20160742457956077, 0.150624942407012, 0.25769641771912577, 0.26987121179699897, 0.12053566500544548, 0.22913857251405717, 0.1837312325835228, 0.24034389927983285, 0.22356590256094933, 0.19515905678272247, 0.10270112808793783, 0.22323860339820384, 0.1563263863325119, 0.21075020022690297, 0.23182210475206375, 0.158794055134058, 0.21014680191874505, 0.18203543350100518, 0.18800890147686006, 0.1374545207247138, 0.2877123003825545, 0.20227185934782027, 0.1515484981238842]\n",
            "Epoch :  1\n",
            "Train Loop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:372: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 Loss 0.3225958049297333\n",
            "Iteration 100 Loss 0.3749157190322876\n",
            "Iteration 200 Loss 0.12199568003416061\n",
            "Iteration 300 Loss 0.04196774587035179\n",
            "Iteration 400 Loss 0.03675088658928871\n",
            "Iteration 500 Loss 0.3476121127605438\n",
            "Iteration 600 Loss 0.31324392557144165\n",
            "Iteration 700 Loss 0.49062299728393555\n",
            "Iteration 800 Loss 0.05823909863829613\n",
            "Iteration 900 Loss 0.36205556988716125\n",
            "Iteration 1000 Loss 0.17896635830402374\n",
            "Iteration 1100 Loss 0.3743111193180084\n",
            "Iteration 1200 Loss 0.08851179480552673\n",
            "Iteration 1300 Loss 0.20544175803661346\n",
            "Iteration 1400 Loss 0.325318843126297\n",
            "Iteration 1500 Loss 0.07994962483644485\n",
            "Iteration 1600 Loss 0.08884931355714798\n",
            "Iteration 1700 Loss 0.4851783514022827\n",
            "Iteration 1800 Loss 0.13645219802856445\n",
            "\n",
            "Epoch = 1\tAccuracy Score = 88.91\n",
            "Learning Rate = 1.9200000000000003e-05\n",
            "\n",
            "loss_list  [0.2243881668895483, 0.14863150790333748, 0.1239036813378334, 0.23277650251984597, 0.14887059964239596, 0.18678105846047402, 0.11946671828627586, 0.17593336142599583, 0.23963235057890414, 0.2563443586230278, 0.16299257874488832, 0.18958363644778728, 0.15025170668959617, 0.20438678115606307, 0.11368346400558949, 0.19695610706694425, 0.22438199631869793, 0.19192304238677024, 0.20510514341294767, 0.18295856546610595, 0.13184045776724815, 0.24984514452517032, 0.19621572345495225, 0.14708507359027861, 0.18510935083031654, 0.17846129834651947, 0.13900015205144883, 0.15912571744993328, 0.1570020031183958, 0.17238333206623793, 0.18766325376927853, 0.14294039495289326, 0.14702969305217267, 0.14672598391771316, 0.20144205559045075, 0.1560348603874445, 0.1244516421109438, 0.19853229951113463, 0.11080566318705679, 0.18387964963912964, 0.13615141911432146, 0.17723952773958446, 0.23233308345079423, 0.15474113672971726, 0.156356842815876, 0.1406217936426401, 0.1443658396601677, 0.14311358910053967, 0.16959177292883396, 0.1478248655796051, 0.1830429330468178, 0.1691227424889803, 0.1567260693758726, 0.16161780133843423, 0.14924344643950463, 0.1398695858195424, 0.13156126141548158, 0.25199964828789234, 0.1323926866054535, 0.16457107104361057, 0.19027310758829116, 0.23974604569375516, 0.2421118475496769, 0.21289009973406792, 0.1986202046275139, 0.15633246153593064, 0.21733702570199967, 0.17357367947697638, 0.12047909684479237, 0.14284637868404387, 0.20508543103933335, 0.19505371823906897, 0.14332322664558889, 0.1457148902118206, 0.21107231564819812, 0.14758947789669036, 0.17068338096141816, 0.18107183389365672, 0.17087882049381733, 0.15715981032699347, 0.13032361418008803, 0.30519919414073227, 0.1930063422769308, 0.20184205360710622, 0.12681988328695298, 0.19205065332353116, 0.19169796034693717, 0.11525244060903787, 0.15339250359684228, 0.11154810134321451, 0.10769523307681084, 0.1118758574128151, 0.14823516607284545, 0.14648556103929877, 0.1684333799406886, 0.14109208583831787, 0.0907175094820559, 0.12731809820979834, 0.1909662125632167, 0.20175153594464063, 0.10833621323108673, 0.14957355950027704, 0.17658772505819798, 0.09285105131566525, 0.11692121997475624, 0.12352651171386242, 0.14213017895817756, 0.16811379808932542, 0.08936842111870646, 0.1351737530902028, 0.17393535654991865, 0.16953258346766234, 0.12134304773062468, 0.1282992860302329, 0.12672287859022618, 0.14654945433139802, 0.15949101466685534, 0.10999720394611359, 0.15126660466194153, 0.10898608276620507, 0.10258698854595423, 0.11379169523715973, 0.09983583823777735, 0.1250238343141973, 0.1591806050390005, 0.20152972117066384, 0.13149262852966787, 0.13048400301486254, 0.13675188980996608, 0.11842265306040645, 0.16609924361109735, 0.16929918117821216, 0.13827898064628244, 0.06895584128797054, 0.1383568862453103, 0.1384190778248012, 0.23737692087888718, 0.1314610756933689, 0.1465074423700571, 0.21667974051088096, 0.1445462368428707, 0.11897097900509834, 0.1234045165590942, 0.1073052143678069, 0.1687954755499959, 0.10828722976148128, 0.0660029306076467, 0.17507101129740477, 0.07497849632054568, 0.0659384498372674, 0.1256934406235814, 0.21947119999676942, 0.08084682552143932, 0.1416714807972312, 0.1183786790817976, 0.13100999854505063, 0.13939605038613082, 0.13062864020466805, 0.06962358332239091, 0.0851006805896759, 0.07085452671162784, 0.10798247912898659, 0.10305870957672596, 0.09655462102964521, 0.08355788746848702, 0.1425254324451089, 0.11268479637801647, 0.14715473148971797, 0.12513611046597362, 0.21106699043884875, 0.1297547402791679, 0.17282891795039176, 0.11531302556395531, 0.1670809743925929, 0.06804989520460367, 0.094184136018157, 0.14338398398831487, 0.14072312954813243, 0.09434777107089758, 0.14814904183149338, 0.10366654274985194, 0.12911632508039475, 0.1586543177254498, 0.19176916163414717, 0.17882800847291946, 0.07958910316228866, 0.17251201570034028]\n",
            "Epoch :  2\n",
            "Train Loop\n",
            "Iteration 0 Loss 0.018333006650209427\n",
            "Iteration 100 Loss 0.01144055649638176\n",
            "Iteration 200 Loss 0.02664347179234028\n",
            "Iteration 300 Loss 0.037629686295986176\n",
            "Iteration 400 Loss 0.04006859287619591\n",
            "Iteration 500 Loss 0.06598690897226334\n",
            "Iteration 600 Loss 0.023520834743976593\n",
            "Iteration 700 Loss 0.10865236073732376\n",
            "Iteration 800 Loss 0.04711872339248657\n",
            "Iteration 900 Loss 0.07640951871871948\n",
            "Iteration 1000 Loss 0.16991126537322998\n",
            "Iteration 1100 Loss 0.049881938844919205\n",
            "Iteration 1200 Loss 0.022899281233549118\n",
            "Iteration 1300 Loss 0.015941642224788666\n",
            "Iteration 1400 Loss 0.012402651831507683\n",
            "Iteration 1500 Loss 0.017407359555363655\n",
            "Iteration 1600 Loss 0.07275030016899109\n",
            "Iteration 1700 Loss 0.07808276265859604\n",
            "Iteration 1800 Loss 0.018288929015398026\n",
            "\n",
            "Epoch = 2\tAccuracy Score = 89.005\n",
            "Learning Rate = 1.5360000000000002e-05\n",
            "\n",
            "loss_list  [0.13667401485145092, 0.07315628351643681, 0.11962335808202625, 0.06706183981150389, 0.0988239323720336, 0.09107811544090509, 0.14862901903688908, 0.05399920754134655, 0.09794425908476115, 0.060391845740377904, 0.05534219034016132, 0.041347360238432884, 0.13154717860743403, 0.051941957185044886, 0.1286230143159628, 0.06627020337618887, 0.1310262165032327, 0.1767780869267881, 0.08711611852049828, 0.08678585328161717, 0.09450645614415407, 0.16004690006375313, 0.07725933119654656, 0.07272423850372434, 0.10527133187279106, 0.03586902217939496, 0.1693711676634848, 0.13382713738828897, 0.15354029154404997, 0.1362582802772522, 0.14358805287629367, 0.13990431781858206, 0.09268605699762703, 0.1011836564168334, 0.11914072763174773, 0.0867325633764267, 0.11233075899071991, 0.10762682743370533, 0.09648916036821902, 0.11109241051599383, 0.07214593952521682, 0.15768937766551971, 0.12718617990612985, 0.1316794464364648, 0.11549127334728837, 0.05884307292290032, 0.12868326203897595, 0.035987552162259816, 0.07433812413364649, 0.07986122108995915, 0.11384147731587291, 0.10491358758881689, 0.09156850259751081, 0.07332239151000977, 0.11700067706406117, 0.08882897384464741, 0.05126061816699803, 0.056859772698953745, 0.11595317372120917, 0.11127713173627854, 0.23691636407747865, 0.1288677791133523, 0.09852222353219986, 0.12279786914587021, 0.13215534202754498, 0.05050124926492572, 0.07685715360566973, 0.11388907991349698, 0.08992970138788223, 0.06891708788461984, 0.08258374175056815, 0.17683612778782845, 0.15630705785006285, 0.06909655928611755, 0.08659637123346328, 0.10101662846282125, 0.09178951680660248, 0.07108127782121301, 0.1481540583074093, 0.08921575071290136, 0.08287273980677128, 0.19053836343809963, 0.12705368017777802, 0.08012934662401676, 0.10253099529072643, 0.051809059269726274, 0.17259732158854604, 0.13019915246404706, 0.06591826872900128, 0.09627481177449226, 0.0850235117599368, 0.06962350970134139, 0.08276569019071758, 0.09205930870957672, 0.07053492860868574, 0.12899637296795846, 0.10253728879615664, 0.0922214281745255, 0.1245355828665197, 0.05708902506157756, 0.11123108854517341, 0.14989625848829746, 0.06963005531579256, 0.05707451328635216, 0.0797442713752389, 0.14840499870479107, 0.08922880608588457, 0.04826694810763001, 0.12309528193436563, 0.0660651432350278, 0.034911421686410905, 0.03769342098385096, 0.09698198991827667, 0.048387646302580835, 0.07444149716757238, 0.0675011801533401, 0.08141296249814331, 0.11211879039183259, 0.061333527276292446, 0.07452426925301552, 0.11745088277384638, 0.08150825859047472, 0.07539910371415318, 0.12317119562067091, 0.09168401295319199, 0.09082097448408603, 0.04248497886583209, 0.11162070985883474, 0.10660856943577528, 0.10128274857997895, 0.048697295133024454, 0.04509534728713334, 0.11061619231477379, 0.07934083719737828, 0.0765639512334019, 0.049230623152107, 0.026319645717740058, 0.0986784623004496, 0.10012929392978549, 0.034448304958641526, 0.06251200311817229, 0.11970673953182995, 0.07616079282015562, 0.10126389563083649, 0.07278486285358668, 0.024308565305545926, 0.09956290852278471, 0.11885477756150067, 0.09297201959416271, 0.02423171140253544, 0.0726643867790699, 0.10146276690065861, 0.10077172331511974, 0.06590850781649352, 0.030117531213909386, 0.09245414333418012, 0.06732781529426575, 0.08878359133377671, 0.06976343533024192, 0.06012550806626678, 0.09234343222342431, 0.09225918841548264, 0.07280926215462387, 0.05111840986646712, 0.03387492937035859, 0.062071489682421085, 0.10941696576774121, 0.10713956207036972, 0.04806113042868674, 0.04893644959665835, 0.05308111924678087, 0.04842864747624844, 0.07904553040862083, 0.08365000614430755, 0.036432331521064044, 0.06646984396502376, 0.09234667778946459, 0.0846059232018888, 0.05652975169941783, 0.05962883555330336, 0.09619338288903237, 0.04798764022998512, 0.01769788363017142, 0.05378089570440352, 0.031072279927320777, 0.06160828857682645, 0.1066433229483664]\n",
            "Epoch :  3\n",
            "Train Loop\n",
            "Iteration 0 Loss 0.14267219603061676\n",
            "Iteration 100 Loss 0.05433148145675659\n",
            "Iteration 200 Loss 0.09276708215475082\n",
            "Iteration 300 Loss 0.020482178777456284\n",
            "Iteration 400 Loss 0.0370650589466095\n",
            "Iteration 500 Loss 0.0060576824471354485\n",
            "Iteration 600 Loss 0.002686461666598916\n",
            "Iteration 700 Loss 0.011727333068847656\n",
            "Iteration 800 Loss 0.007290482986718416\n",
            "Iteration 900 Loss 0.03327232226729393\n",
            "Iteration 1000 Loss 0.00448885140940547\n",
            "Iteration 1100 Loss 0.12617607414722443\n",
            "Iteration 1200 Loss 0.030412986874580383\n",
            "Iteration 1300 Loss 0.0017691832035779953\n",
            "Iteration 1400 Loss 0.0023751924745738506\n",
            "Iteration 1500 Loss 0.014145719818770885\n",
            "Iteration 1600 Loss 0.004117513075470924\n",
            "Iteration 1700 Loss 0.017388351261615753\n",
            "Iteration 1800 Loss 0.19867315888404846\n",
            "\n",
            "Epoch = 3\tAccuracy Score = 89.18\n",
            "Learning Rate = 1.2288000000000002e-05\n",
            "\n",
            "loss_list  [0.03426342597231269, 0.05922738583758473, 0.08239745763130486, 0.047331956890411676, 0.038173336628824474, 0.029757812758907674, 0.1292049114126712, 0.09709350308403372, 0.11603939016349614, 0.07713347496464848, 0.04759580185636878, 0.11836193334311247, 0.03932462045922876, 0.02556286402978003, 0.026635365141555668, 0.12244686326012015, 0.037961516552604734, 0.029545437591150404, 0.0929104059934616, 0.0375389099586755, 0.052551907813176514, 0.0646487485151738, 0.09477580143138767, 0.06578896418213845, 0.012239902466535568, 0.019695288850925863, 0.06405226836213843, 0.08277204218320548, 0.025429928116500376, 0.08911270112730563, 0.009300347045063972, 0.07563064377754927, 0.01726080656517297, 0.059835147997364405, 0.05170644661411643, 0.0799369091168046, 0.07703826208598911, 0.06335630100220442, 0.12483645714819432, 0.050561585230752826, 0.031548502994701265, 0.04136199620552361, 0.054054760839790106, 0.16615821570158004, 0.06128006167709828, 0.06256809737533331, 0.021013524872250854, 0.02662266620900482, 0.07090711663477123, 0.08914035460911691, 0.09557488490827382, 0.07664113957434893, 0.0438974394928664, 0.05331960269249976, 0.09040852105244994, 0.09686877969652415, 0.06554649639874696, 0.06892136200331152, 0.04784139483235776, 0.05450218457262963, 0.057163166953250764, 0.06403466807678342, 0.06792030218057335, 0.0500207494944334, 0.07873200769536197, 0.03249364388175309, 0.020206561754457654, 0.044832980772480366, 0.05255054535809904, 0.07302699689753353, 0.0327955637825653, 0.056044694408774375, 0.12160905739292502, 0.04932153057307005, 0.13128010607324542, 0.018356161890551448, 0.03782897861674428, 0.04368939544074237, 0.034916697349399325, 0.025035712448880077, 0.05917221675626934, 0.04685377352871001, 0.006914745876565575, 0.042576817993540315, 0.02939691359642893, 0.0850190192926675, 0.04121153076412156, 0.12449214281514287, 0.10038490500301123, 0.06198768212925643, 0.033076709043234585, 0.042818618821911514, 0.047900620684959, 0.0185401544906199, 0.11996014053001999, 0.04778213519603014, 0.02741775372996926, 0.035799092170782386, 0.07173270324710757, 0.04676136435009539, 0.03768301538657397, 0.017498760088346898, 0.06762578941415995, 0.05914807806257159, 0.033248086925596, 0.0474555617198348, 0.02573472971562296, 0.07048729669768364, 0.017588218627497553, 0.033567663631401956, 0.040597448404878375, 0.09374405932612717, 0.11705293788108975, 0.04043111971113831, 0.021365132136270403, 0.018121799058280885, 0.06228939110878855, 0.11792604583315551, 0.06598966382443905, 0.019844052381813526, 0.02749945903196931, 0.026707960315980016, 0.03815857345471159, 0.03503452586010099, 0.0088952622609213, 0.028160603647120298, 0.04216086238157004, 0.04099035437684506, 0.09127842148300261, 0.01706020231358707, 0.06885610963217914, 0.04880019926931709, 0.0638194139348343, 0.05598123245872557, 0.02107063326984644, 0.019284220063127577, 0.07343325456604362, 0.03544117044657469, 0.02387900445610285, 0.01612032300326973, 0.00701826912118122, 0.11532384671736509, 0.11686578409280628, 0.07950984919443727, 0.011018149880692362, 0.016156725119799376, 0.02689892305061221, 0.10587366942781955, 0.008414266700856387, 0.09705785582773388, 0.04414541721343994, 0.028401110041886567, 0.07965257279574871, 0.0380387393059209, 0.02061320496723056, 0.016983366082422437, 0.0373244610382244, 0.08147824089974165, 0.10336708084214478, 0.06735225224401802, 0.09268843471072614, 0.0400651590898633, 0.04462282317690551, 0.07557287171948701, 0.09627689307089896, 0.05608124705031514, 0.03475570739246905, 0.01105232648551464, 0.06051865397021174, 0.013464387552812696, 0.05162148734088987, 0.0380868881708011, 0.04293252432253212, 0.026007023197598754, 0.06105194627307355, 0.06952234390191733, 0.04523604356218129, 0.01568497489206493, 0.05185968745499849, 0.05414130024146289, 0.047362126235384494, 0.0328520268201828, 0.04704737197607756, 0.02510202433913946, 0.051768144487869, 0.03213598495349288, 0.055757924914360046]\n",
            "Epoch :  4\n",
            "Train Loop\n",
            "Iteration 0 Loss 0.0028131138533353806\n",
            "Iteration 100 Loss 0.05744273215532303\n",
            "Iteration 200 Loss 0.002722539007663727\n",
            "Iteration 300 Loss 0.004660445731133223\n",
            "Iteration 400 Loss 0.005126654170453548\n",
            "Iteration 500 Loss 0.06369232386350632\n",
            "Iteration 600 Loss 0.007086107041686773\n",
            "Iteration 700 Loss 0.005118715111166239\n",
            "Iteration 800 Loss 0.0064566051587462425\n",
            "Iteration 900 Loss 0.0035394455771893263\n",
            "Iteration 1000 Loss 0.0026804725639522076\n",
            "Iteration 1100 Loss 0.016687138006091118\n",
            "Iteration 1200 Loss 0.0015297802165150642\n",
            "Iteration 1300 Loss 0.003721591318026185\n",
            "Iteration 1400 Loss 0.0035276319831609726\n",
            "Iteration 1500 Loss 0.0033636419102549553\n",
            "Iteration 1600 Loss 0.0031437978614121675\n",
            "Iteration 1700 Loss 0.0019182611722499132\n",
            "Iteration 1800 Loss 0.0009670243598520756\n",
            "\n",
            "Epoch = 4\tAccuracy Score = 89.725\n",
            "Learning Rate = 9.830400000000002e-06\n",
            "\n",
            "loss_list  [0.048005972616374494, 0.03608057298697531, 0.043216132011730225, 0.02963582754600793, 0.0441365948645398, 0.05017696460708976, 0.014104907435830682, 0.02670637210831046, 0.017465851770248265, 0.07037493530660868, 0.05554037659894675, 0.010218284145230428, 0.03445621378486976, 0.013326736190356315, 0.09549781698151491, 0.03521752624073997, 0.07058210484683514, 0.01837701767217368, 0.05127649237401784, 0.008902341802604496, 0.019134516594931483, 0.06650051712058484, 0.0071211867732927205, 0.0423984719091095, 0.010954732750542462, 0.05232261478086002, 0.016971333511173727, 0.005968503095209599, 0.008591727341990919, 0.018804187700152398, 0.06704073359724134, 0.014556175726465882, 0.07441781773231923, 0.04974874519975856, 0.102617724891752, 0.03208945160731673, 0.009341080952435733, 0.09420015616342425, 0.05510792848654091, 0.02924133900087327, 0.050789076113142075, 0.03376273897010833, 0.03192842621356249, 0.02599776324350387, 0.029865644150413574, 0.005974527192302048, 0.06725003242027014, 0.031227277463767678, 0.05233361561549828, 0.07675335458479822, 0.023611556959804148, 0.0483535551931709, 0.040769639797508715, 0.007409090851433575, 0.014580508135259152, 0.0395334857632406, 0.012826091086026281, 0.04683044051053002, 0.04879411373985931, 0.020068863604683428, 0.0048375798156484965, 0.01751454846234992, 0.023577814921736717, 0.010310564935207368, 0.04631603680318221, 0.05327124317409471, 0.021141432924196124, 0.049735317419981585, 0.03244274760363623, 0.00491273554507643, 0.0518675412517041, 0.040191234124358745, 0.03965258938260376, 0.023958539543673395, 0.05447586472146213, 0.01011634764727205, 0.014124443987384439, 0.003403053153306246, 0.05321860054973513, 0.06374394182348624, 0.031213830644264817, 0.025588533864356576, 0.047806750307790934, 0.04236918803071603, 0.019843560410663486, 0.014025405771099031, 0.04449253452476114, 0.012296961969695985, 0.017547853023279457, 0.035385017679072914, 0.02116874686907977, 0.05933555131778121, 0.06084931998047978, 0.02162023102864623, 0.012674835231155156, 0.07810971565777436, 0.009934984636493028, 0.06337615095544606, 0.06015712118241936, 0.044520139950327574, 0.008577349444385618, 0.016874228417873383, 0.022424238780513406, 0.024115297594107687, 0.03197326426161453, 0.04435393675230444, 0.015407147945370524, 0.03823905816534534, 0.014709774893708527, 0.0075677602086216215, 0.0059837541077286, 0.08085690446314402, 0.06303584065753967, 0.014268396026454865, 0.04302694511134177, 0.014062109543010593, 0.005784005182795227, 0.007347793900407851, 0.0024785700952634215, 0.04494890988571569, 0.039882282761391254, 0.008325784583576024, 0.052657213411293924, 0.009489716950338335, 0.04654650640441105, 0.015988173824734987, 0.04109428016236052, 0.017051530978642405, 0.052461130486335605, 0.025220788666047156, 0.022627008496783674, 0.021855308057274668, 0.03200012652669102, 0.042795576225034895, 0.05700831963913515, 0.060837369551882146, 0.0528026997577399, 0.04521806391421705, 0.008723922236822546, 0.06305350845213979, 0.0340101869776845, 0.00859657812397927, 0.04803983378224075, 0.012716066022403539, 0.0033860344672575595, 0.010013948730193078, 0.007640239223837853, 0.02634746063267812, 0.014625367743428796, 0.0180181595380418, 0.020050215208902954, 0.005802675377344713, 0.041278047300875184, 0.027037857827963307, 0.04143663965514861, 0.029417372803436592, 0.01476371284807101, 0.05820949579356238, 0.05269282746594399, 0.018796058534644545, 0.05074419947341084, 0.05199752850458026, 0.0059624791610985994, 0.011971664207521826, 0.009555815637577325, 0.00577226763125509, 0.08051961547462269, 0.042117531620897354, 0.01642088838852942, 0.053933869657339525, 0.008119078539311885, 0.01927459645085037, 0.003334809758234769, 0.005287805089028552, 0.026003560185199604, 0.037542964093154295, 0.01167690366273746, 0.011457769060507416, 0.009876634902320802, 0.03126208359608427, 0.005165552214020863, 0.024391192465554924, 0.0197308779519517, 0.022965202346676962, 0.03586444372776896, 0.060930027364520356, 0.05257324537960813]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bD2K7J0c3__r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance Ananlysis"
      ],
      "metadata": {
        "id": "A9inIAXJ5koZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(epoch_loss_list)\n",
        "loss_epoch =[]\n",
        "for i in range(len(epoch_loss_list)):\n",
        "  loss_epoch.append(sum(epoch_loss_list[i])/len(epoch_loss_list[i]))\n",
        "\n",
        "loss_epoch"
      ],
      "metadata": {
        "id": "agnKkmWcpxpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1df463-ad57-4c41-ad95-2cb01ffd76c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27982749256011563,\n",
              " 0.15223233753536397,\n",
              " 0.09003073877273968,\n",
              " 0.054190723233131594,\n",
              " 0.032241830911162395]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch =[0,1,2,3,4]\n",
        "epoch_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZjFAW3dlfzc",
        "outputId": "a3572d10-cd12-4517-d7ed-0bd4204ffbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[88.47, 88.91, 89.005, 89.18, 89.725]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        " \n",
        "def model_plot(x,y,title):\n",
        "\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "d0kciGl3klWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_plot(num_epoch,epoch_accuracy,\"Accuracy Plot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "E9muDqchklaV",
        "outputId": "99877dce-0347-49ad-b77b-428cc112408f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_plot(num_epoch,loss_epoch,\"Loss Plot\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8tMSaXzUHuzS",
        "outputId": "87bd00d4-0ffe-4239-812a-d05b2c9f22ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        " \n",
        "# assign data\n",
        "mydata =[]\n",
        "for i in range(len(epoch_accuracy)):\n",
        "  mydata.append([num_epoch[i],epoch_accuracy[i]])\n",
        "\n",
        "# create header\n",
        "head = [\"Epoch\", \"Accuracy\"]\n",
        " \n",
        "# display table\n",
        "print(tabulate(mydata, headers=head, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CKc46vLHu2n",
        "outputId": "cf2f9e1d-906f-43d9-c688-e12e93245570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|   Epoch |   Accuracy |\n",
            "+=========+============+\n",
            "|       0 |     88.47  |\n",
            "+---------+------------+\n",
            "|       1 |     88.91  |\n",
            "+---------+------------+\n",
            "|       2 |     89.005 |\n",
            "+---------+------------+\n",
            "|       3 |     89.18  |\n",
            "+---------+------------+\n",
            "|       4 |     89.725 |\n",
            "+---------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata1 =[]\n",
        "for i in range(len(loss_epoch)):\n",
        "  mydata1.append([num_epoch[i],loss_epoch[i]])\n",
        "\n",
        "# create header\n",
        "head = [\"Epoch\", \"Loss\"]\n",
        " \n",
        "# display table\n",
        "print(tabulate(mydata1, headers=head, tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tIvdtvqHu7e",
        "outputId": "137793bd-c0d5-4a07-8f8e-f9b72d4ffc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+\n",
            "|   Epoch |      Loss |\n",
            "+=========+===========+\n",
            "|       0 | 0.279827  |\n",
            "+---------+-----------+\n",
            "|       1 | 0.152232  |\n",
            "+---------+-----------+\n",
            "|       2 | 0.0900307 |\n",
            "+---------+-----------+\n",
            "|       3 | 0.0541907 |\n",
            "+---------+-----------+\n",
            "|       4 | 0.0322418 |\n",
            "+---------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ONNX model"
      ],
      "metadata": {
        "id": "OvxmRwcR_QLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWWea1gdHs7k",
        "outputId": "9e207953-13e7-4f77-94cc-0ad50505ef1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loaded the trained bert model."
      ],
      "metadata": {
        "id": "3uuB8LIr5qpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path ='/content/drive/MyDrive/DLOPS_project/3.bin'\n",
        "model = SentimentClassifier(BERT_MODEL)\n",
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "model"
      ],
      "metadata": {
        "id": "gtJLDqn4_RXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726a4214-0eb5-4ca3-8ecb-5604a55ec1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentimentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TRAIN_MAX_LEN = 140\n",
        "VALID_MAX_LEN = 140\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "BERT_MODEL = 'bert-base-uncased'\n",
        "LEARNING_RATE = 3e-5\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "\n",
        "train_dataset = util_tokenizer(\n",
        "    text = df_train['review'].values,\n",
        "    targets = df_train['sentiment'].values,\n",
        "    tokenizer = tokenizer,\n",
        "    max_len = TRAIN_MAX_LEN\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = TRAIN_BATCH_SIZE,\n",
        "    shuffle = False,\n",
        ")\n",
        "\n",
        "\n",
        "for bi, d in enumerate(train_data_loader):\n",
        "  ids = d[\"ids\"]\n",
        "  mask = d[\"mask\"]\n",
        "  token_type_ids = d[\"token_type_ids\"]\n",
        "  targets = d[\"targets\"]\n",
        "  break"
      ],
      "metadata": {
        "id": "LVZrSySSORHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Converting in onnx"
      ],
      "metadata": {
        "id": "8Wt7sns_5yrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Input to the model\n",
        "\n",
        "x = (ids,mask,token_type_ids)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model,                      # model being run\n",
        "                  x,                          # model input (or a tuple for multiple inputs)                       \n",
        "                  \"/content/drive/MyDrive/DLOPS_project/sentiment_bert.onnx\", # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  )\n",
        "print(\"successfully converted to onnx\")\n",
        "\n",
        "\n",
        "#onnx.checker.check_model(onnx_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No2UcSpdHyj7",
        "outputId": "cb6c849f-1654-4c4c-ee47-f693bdebc162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "successfully converted to onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AZ_ejLwLden8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inferencing on Pytorch"
      ],
      "metadata": {
        "id": "cffGhx_5heSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"The movie was initially boring but it was good in the second half and I didn't find the plot of the movie interesting\"\n",
        "#text_neg =\"The move was so bad\""
      ],
      "metadata": {
        "id": "A9NSSYIwrAad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "BERT_MODEL = 'bert-base-uncased'\n",
        "MAX_LEN = 160\n",
        "\n",
        "start = time.time()\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "text = text.strip()\n",
        "\n",
        "\n",
        "inputs = tokenizer.encode_plus(\n",
        "    text,\n",
        "    add_special_tokens = True,\n",
        "    max_length = MAX_LEN,\n",
        "    pad_to_max_length = True\n",
        ")\n",
        "ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n",
        "token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "ids = ids.to(device, dtype=torch.long)\n",
        "mask = mask.to(device, dtype=torch.long)\n",
        "token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "\n",
        "path = '/content/drive/MyDrive/DLOPS_project/3.bin'\n",
        "model = SentimentClassifier(BERT_MODEL)\n",
        "model.load_state_dict(torch.load(path))\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "#print(predicted)\n",
        "predicted = predicted.detach().cpu().numpy()\n",
        "predict_sentiment=predicted[0]\n",
        "predict_score=outputs[0][predict_sentiment].item()\n",
        "#print(predict_score)\n",
        "\n",
        "print(\"PyTorch Inference time = {} ms\".format(time.time() - start))\n",
        "if predict_sentiment ==0:\n",
        "  print(\"The sentiment is positive\")\n",
        "else:\n",
        "  print(\"The sentiment is negative\")\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0prpmCeWrJdp",
        "outputId": "a84eaf53-c50e-4a5a-ad82-25458e49c38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Inference time = 5.874268054962158 ms\n",
            "The sentiment is negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Jou4aIydpu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"The movie was so good, I really liked it\"\n",
        "text_neg =\"The move was extremely bad\""
      ],
      "metadata": {
        "id": "QpuZB5FmdqEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "BERT_MODEL = 'bert-base-uncased'\n",
        "MAX_LEN = 160\n",
        "\n",
        "start = time.time()\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(BERT_MODEL)\n",
        "text_neg = text_neg.strip()\n",
        "\n",
        "\n",
        "inputs = tokenizer.encode_plus(\n",
        "    text,\n",
        "    add_special_tokens = True,\n",
        "    max_length = MAX_LEN,\n",
        "    pad_to_max_length = True\n",
        ")\n",
        "ids = torch.tensor(inputs[\"input_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "mask = torch.tensor(inputs[\"attention_mask\"], dtype=torch.long).unsqueeze(0)\n",
        "token_type_ids = torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "ids = ids.to(device, dtype=torch.long)\n",
        "mask = mask.to(device, dtype=torch.long)\n",
        "token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "\n",
        "path = '/content/drive/MyDrive/DLOPS_project/3.bin'\n",
        "model = SentimentClassifier(BERT_MODEL)\n",
        "model.load_state_dict(torch.load(path))\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "outputs = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "#print(outputs)\n",
        "\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "#print(predicted)\n",
        "predicted = predicted.detach().cpu().numpy()\n",
        "predict_sentiment=predicted[0]\n",
        "predict_score=outputs[0][predict_sentiment].item()\n",
        "#print(predict_score)\n",
        "\n",
        "print(\"PyTorch Inference time = {} ms\".format(time.time() - start))\n",
        "if predict_sentiment ==0:\n",
        "  print(\"The sentiment is positive\")\n",
        "else:\n",
        "  print(\"The sentiment is negative\")\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f115cc79-5980-4be9-d58a-ce08e2921681",
        "id": "HpfXlzvCdqEd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Inference time = 8.51868724822998 ms\n",
            "The sentiment is negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QiLVWvnYv0v6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}